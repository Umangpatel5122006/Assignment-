# -*- coding: utf-8 -*-
"""Lab_6_Q1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uaPeXsv7A1h2zMOJopNW7MsyRu2NcEku
"""

from collections import defaultdict

graph = defaultdict(dict)

def add_edge(u,v,dist):
  graph[u][v]=dist
  graph[v][u]=dist
  graph[u][u]=0
  graph[v][v]=0

city_map={
    0 : "Chicago",
    1 : "Detroit",
    2 : "Cleveland",
    3 : "Indianapolis",
    4 : "Columbus",
    5 : "Buffalo",
    6 : "Pittsburgh",
    7 : "Syracuse",
    8 : "Philadelphia",
    9 : "Baltimore",
    10 : "New York",
    11 : "Providence",
    12 : "Boston",
    13 : "Portland"
}

add_edge(0,1,283)
add_edge(0,2,345)
add_edge(0,3,182)
add_edge(3,4,176)

add_edge(1,2,169)
add_edge(1,5,256)
add_edge(2,4,144)
add_edge(2,6,134)
add_edge(2,5,189)
add_edge(4,6,185)

add_edge(5,7,150)
add_edge(5,6,215)
add_edge(6,9,247)
add_edge(6,8,97)

add_edge(9,8,101)

add_edge(7,12,312)
add_edge(7,10,254)
add_edge(7,8,253)
add_edge(8,10,97)

add_edge(10,12,215)
add_edge(10,11,181)

add_edge(12,11,50)
add_edge(12,13,107)

class HeuristicTable:
    def __init__(self):
        #  city -> heuristic mapping
        self.table = {}

    def add_city(self, city_name: str, heuristic_value: float):
        """Add or update a heuristic value for a given city."""
        self.table[city_name] = heuristic_value

    def get_h_value(self, city_name: str):

        return self.table.get(city_name, None)  # returns None if city not found

ht=HeuristicTable()

entries = [
    ("Boston", 0),
    ("Providence", 50),
    ("Portland", 107),
    ("New York", 215),
    ("Philadelphia", 270),
    ("Baltimore", 360),
    ("Syracuse", 260),
    ("Buffalo", 400),
    ("Pittsburgh", 470),
    ("Cleveland", 550),
    ("Columbus", 640),
    ("Detroit", 610),
    ("Indianapolis", 780),
    ("Chicago", 860),
]

for city, h in entries:
    ht.add_city(city, h)

class Node:
  def __init__(self,state,parent,action,path_cost,h_n,f_value=0):
    self.state = state
    self.parent = parent
    self.action = action
    self.path_cost = path_cost
    self.h_n=h_n
    self.f_value = f_value

  def __lt__(self, other):
    return self.f_value < other.f_value

class Problem:
  def __init__(self,start,goal,graph,ht):
    self.initial_state=start
    self.goal_state=goal
    self.matrix=graph
    self.total_explored_states=0
    self.ht=ht

  def exploring(self):
    self.total_explored_states+=1


  def initial(self):
    return self.initial_state

  def is_goal(self,state):
    return state==self.goal_state

  def actions(self,state):
    available_state_action=[]
    for neighbor_state in self.matrix[state].keys():
      if neighbor_state != state:
        available_state_action.append(neighbor_state)
    return available_state_action#contain state as element

  def result(self,state,state_by_action):
    return state_by_action

  def action_cost(self,St,a,end):
    return self.matrix[St][end]
  def get_h_value(self,state):
    return self.ht.get_h_value(city_map[state])

def Expand(problem,node):
  new_nodes=[]
  s=node.state

  for action in problem.actions(s):
    new_state=problem.result(s,action)
    cost = node.path_cost + problem.action_cost(s,action,new_state)

    child= Node(state=new_state,parent=node,action=action,path_cost=cost,h_n=problem.get_h_value(new_state))
    new_nodes.append(child)
  return new_nodes

class prio_queue:

  def __init__(self, l=None):
    self.l = l if l is not None else []
    if self.l:
      self.heapify()

  def isEmpty(self):
    return len(self.l) == 0

  def heapify(self):
    n = len(self.l)
    # Start from the last non-leaf node and go backwards to the root (index 0)
    # Last non-leaf node is at index (n // 2) - 1
    #              (start,stop,step)
    for i in range((n // 2) - 1, -1, -1):
        self._sift_down(i)


  def addlast(self, a):
    self.l.append(a)

    self._sift_up(len(self.l) - 1)

  def pop_left(self):
    if len(self.l) == 0:
      print("No ele to pop")
      return None

    temp = self.l[0]

    last_val = self.l.pop() # Removes the last element

    if len(self.l) > 0:
      self.l[0] = last_val
      # Push this new root down to its correct position
      self._sift_down(0)

    return temp

  def _sift_up(self, idx):
    parent = (idx - 1) // 2
    # While we are not at root AND current element is smaller than parent
    while idx > 0 and self.l[idx] < self.l[parent]:
      # Swap them
      self.l[idx], self.l[parent] = self.l[parent], self.l[idx]
      # Move up
      idx = parent
      parent = (idx - 1) // 2

  def _sift_down(self, idx):
    n = len(self.l)
    smallest = idx
    left_child = 2 * idx + 1
    right_child = 2 * idx + 2

    if left_child < n and self.l[left_child] < self.l[smallest]:
      smallest = left_child

    if right_child < n and self.l[right_child] < self.l[smallest]:
      smallest = right_child

    if smallest != idx:
      self.l[idx], self.l[smallest] = self.l[smallest], self.l[idx]
      self._sift_down(smallest)

"""##  Greedy Best-First Search



"""

def greedy_best_first(problem):
  initial_state_id = problem.initial()
  h_value_initial = problem.get_h_value(initial_state_id)
  initial_node = Node(state=initial_state_id, parent=None, action=None, path_cost=0, h_n=h_value_initial, f_value=h_value_initial)

  frontier = prio_queue()
  frontier.addlast(initial_node)

  reached_lookup = {initial_node.state: initial_node}

  while not frontier.isEmpty():
    node = frontier.pop_left()
    problem.exploring()

    if problem.is_goal(node.state):
        return node

    for child in Expand(problem, node):
        # For Greedy Best-First Search, f_value is h_n
        child.f_value = child.h_n
        s = child.state

        if s not in reached_lookup or child.f_value < reached_lookup[s].f_value:
          reached_lookup[s] = child
          frontier.addlast(child)

  return None

def best_way(goal_node):
  way = []
  node = goal_node

  while node is not None:
    way.append(node.state)
    node = node.parent

  way.reverse()
  return way

st_state=7
goal_state=0
cost_arr=[]
vis=set()
cost_curr=0

myprob= Problem(st_state,goal_state,graph,ht) 
result_node = greedy_best_first(myprob)
if result_node:
  print(f"Path from {city_map[st_state]} to {city_map[goal_state]}: {best_way(result_node)}")
  print(f"Total cost: {result_node.path_cost}")
  print()
else:
  print(f"No path found from {city_map[st_state]} to {city_map[goal_state]}")
print(f"Total states explored is :{myprob.total_explored_states}")

"""## Implement A* Search Algorithm



"""

def a_star_search(problem):
  initial_state_id = problem.initial()
  h_value_initial = problem.get_h_value(initial_state_id)
  initial_node = Node(state=initial_state_id, parent=None, action=None, path_cost=0, h_n=h_value_initial, f_value=h_value_initial + 0)

  frontier = prio_queue()
  frontier.addlast(initial_node)

  reached_lookup = {initial_node.state: initial_node}

  while not frontier.isEmpty():
    node = frontier.pop_left()
    problem.exploring()

    if problem.is_goal(node.state):
        return node

    for child in Expand(problem, node):
        child.f_value = child.path_cost + child.h_n
        s = child.state

        if s not in reached_lookup or child.f_value < reached_lookup[s].f_value:
          reached_lookup[s] = child
          frontier.addlast(child)

  return None

st_state = 0 # Chicago
goal_state = 12 # Boston

# --- Greedy Best-First Search ---
print("\n--- Greedy Best-First Search ---")
myprob_greedy = Problem(st_state, goal_state, graph, ht)
result_node_greedy = greedy_best_first(myprob_greedy)

if result_node_greedy:
  print(f"Path from {city_map[st_state]} to {city_map[goal_state]}: {best_way(result_node_greedy)}")
  print(f"Total cost: {result_node_greedy.path_cost}")
else:
  print(f"No path found from {city_map[st_state]} to {city_map[goal_state]} using Greedy Best-First Search")
print(f"Total states explored by Greedy Best-First Search: {myprob_greedy.total_explored_states}")

# --- A* Search ---
print("\n--- A* Search ---")
# Reset explored states for A* (or create a new Problem instance)
myprob_astar = Problem(st_state, goal_state, graph, ht) # Creating a new instance to reset explored states
result_node_astar = a_star_search(myprob_astar)

if result_node_astar:
  print(f"Path from {city_map[st_state]} to {city_map[goal_state]}: {best_way(result_node_astar)}")
  print(f"Total cost: {result_node_astar.path_cost}")
else:
  print(f"No path found from {city_map[st_state]} to {city_map[goal_state]} using A* Search")
print(f"Total states explored by A* Search: {myprob_astar.total_explored_states}")

"""## Compare and Summarize Results

### Comparison:

**Greedy Best-First Search:**
-   **Path:** Chicago (0) -> Cleveland (2) -> Buffalo (5) -> Syracuse (7) -> Boston (12)
-   **Total Cost:** 996
-   **Total States Explored:** 5

**A* Search:**
-   **Path:** Chicago (0) -> Cleveland (2) -> Pittsburgh (6) -> Philadelphia (8) -> New York (10) -> Boston (12)
-   **Total Cost:** 888
-   **Total States Explored:** 10


"""